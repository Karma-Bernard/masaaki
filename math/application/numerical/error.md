---
sort: 1
---

# 误差

## **1.1 计算对象**

------为什么滴定管用四位有效数字？

------有效数字是什么？

------啊？？

​科学界目前公认的有三大类科学研究方法:理论方法,实验方法和科学计算方法.这三类方法相辅相成,互为补充.不说别的,就从最基本的多电子薛定谔方程的求解我们就束手无策了.因此可以说,基础理论只解决了定性问题.但它没给出,尤其是复杂问题,具体的求解方法.这里面仍然包含了大量数学上的困难和挑战,现在我们仍然无法通过现有的手段解决.并且,实验方法中某些特定条件实现起来过于昂贵,有些条件过于苛刻难于达到,也使得目前许多实验都用数值模拟实验来代替.因此"把一些玩意算出来"其实是很有必要的.那么怎么算?是我们应该认识的,学习的.

**E.G.-1.1.1**

显然地,定积分可以通过我们熟悉的Newton-Leibnitz公式计算:
$$
\int_a^b {f(x){\text{d}}x}  = F(b) - F(a)
$$
但,学过微积分的,但凡是学过的!都会知道绝大部分的函数,是找不到初等函数表示的原函数的!就算能找得到级数解,也很难以计算.换句话说,就是几乎所有的函数都"积不出来".

所以说,对于大多数定积分的计算,我们还是需要在数值上进行计算的.

**E.G.-1.1.2**

对于含有个未知数的线性方程组$${\mathbf{A}}\vec x = \vec\beta $$,只要$\det\mathbf{A}\ne0$,那当然方程组就有唯一解.我们使用Cramer法则可以直接求解,但是需要计算$n+1$个行列式.如果我们只有100个未知数呢?100个?这意味着我们需要进行9.4×10^159^次浮点运算.即便使用每秒双精度浮点运算9.3×10^16^次运算的神威太湖之光来算,我们还需要超过10^127^亿年的计算时间,这比宇宙还老太多了啊喂?!

**E.G.-1.1.3**

代数基本定理告诉我们,复系数一元$n$次多项式有$n$个复根.然而我们也知道,五次以上的代数方程便没有一般求根公式.这就告诉我们,即便是求一元多项式的根,《线性代数》课程也没有告诉我们可行的求解方法,因此必须设计新的办法来求解,而许多科学与工程计算问题中都需要求解多项式的根.

从这几个例子我们可以看到:大量实际问题我们无法得到其解析解的表达式(虽说有时候即便可以写成积分或者级数形式,实际计算时还需要设计快速算法),因此我们在此需要研究如何有效(用合理的计算量)并高精度地(相对小的误差)得到一个问题的近似解(原因是其解析解无法显式给出).

## **1.2 误差的来源**

从上面例子我们已经看到,通常我们在科学与工程计算问题中需要在事先给定的精度要求下,通过构造性的方法给出在一定计算量下的近似解,由于解析解通常无法得到,所以我们得到的解总是存在一定的误差的,如果说有这玩我们就不如和他伴随好了,但是如果承认它一直存在.那么有以下两个问题需要特别关注:

```note
1.如何估计近似解与原精确解之间的误差大小?

2.如何保证算法的数值稳定性:即控制误差的传递,使得不会由于计算步骤的增加,误差无限制地增长.
```

换句话就是,如果误差应是存在,那我们用何种方法能控制它,能知道它的范围?能不让误差一步步被放大或者使得计算结果失真?这是我们应讨论的.

下面我们先看看误差的来源,或者说分类.

**Def-1.2.1**

误差通常有以下四类,其中前两类在这里暂不考虑,它们更偏向技术性的问题.因此我们主要考虑后两类误差,这是在计算过程中很重要的.
```note
**模型误差**:即建模时会舍弃部分次要因素而产生的误差.

**测量误差**:即测量数据如温度,压强,速度,电导率等带来的误差.

**截断误差（truncation error）**:这是由于使用近似问题代替原问题或者使用近似方法求解而产生的误差.如:

$\abs {x}\ll1$时,可以用$x$近似代替换:
$$
\sin x=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots
$$
**舍入误差（roundoff error）**:这是由于计算机字长有限带来的浮点数运算产生的误差,如$$π=3.1415926535897......$$是无理数.但囿于计算机字长有限,无法准确表示它,只能截断:如果用6位数字表示$$3.14159$$那么误差即为$$error=0.0000026535...$$
```
关于误差的数学定义我们其实已经很熟悉了,这甚至是很自然的:

**Def-1.2.2**

设$x^*$是某个实数$x$的一个近似值,则称$x-x^*$为近似值$x^*$的**误差**.

称$\abs{x-x^*}$为$x^*$的**绝对误差**,若$x\ne0$,则称$\Large\abs{\frac{x-x^*}{x}}$为$x^*$的**相对误差**.

不过一般而言,我们并不知道的准确值,因此我们只能估计出绝对误差的一个范围,即:$\abs{x-x^*}\leqslant\eta$

此时称$\eta$为$x^*$的**绝对误差限(界)**,记作$\varepsilon(x^*)$.

同样地:若$$x^* \ne 0$$，称${\varepsilon _r}\left( {x^*} \right) = \frac{{\varepsilon \left( {x^*} \right)}}{{x^*}} = \frac{\eta }{{x^*}}$为$x^*$的**相对误差限(界)**.

干巴巴的不知道干啥?我们看一个例子:

**E.G.-1.2.1**

$π=3.1415926535897......$是无理数.但囿于计算机字长有限,无法准确表示它,只能截断:如果用$6$位数字表示:$$3.14159$$那么误差即为$error=0.0000026535......$这坨舍入误差的其中一个绝对误差限就可以取什么呢比:$error$绝对值大就完事了,管他有几位:$\eta=3\times 10^{-6}$,那么它的相对误差限就理应可以!注意是可以是$1\times 10^{-6}$了.

我们刚刚不是提出了一个暴论:管他有几位吗?那么数据的位数究竟有多重要:我们不妨试想一下,在实数的准确值已知的情况下,如果我们要去拿这玩当物理常数去算,通常我们会用一个听到耳朵起茧子的法则:四舍五入(化学中涉及末位数则是"四舍六入五成双")为什么我们要这么做:我们来看一下这样做的理由:

理想气体状态方程$pV = nRT$中的常数$R = 8.314472{\text{J}} \cdot {\text{mo}}{{\text{l}}^{ - 1}} \cdot {{\text{K}}^{ - 1}}$:

一般计算取前三位或者前四位代入方程,譬如:
$$
\begin{gathered}
  \left| {R - 8.31} \right| = 0.004472 \leqslant 0.5 \times {10^{ - 2}} \hfill \\
  \left| {R - 8.314} \right| = 0.000472 \leqslant 0.5 \times {10^{ - 3}} \hfill \\ 
\end{gathered} 
$$
Avogadro常数${N_A} = 6.02214076 \times {10^{23}}{\text{mo}}{{\text{l}}^{ - 1}}$:

一般计算取前三位或者前四位代入方程,譬如:
$$
\begin{gathered}
  \left| {{N_A} - 6 \times {{10}^{23}}} \right| = 0.2214076 \times {10^{22}} \leqslant 0.5 \times {10^{22}} \hfill \\
  \left| {{N_A} - 6.02 \times {{10}^{23}}} \right| = 0.214076 \times {10^{21}} \leqslant 0.5 \times {10^{21}} \hfill \\ 
\end{gathered}
$$
发现了一件什么事?绝对误差限总被控制在(或者说能够取到)$0.5\times10^\nu$之上,$$0.5$$这个数我们可太熟悉了,这不就是四舍五入的边界吗?

由此我们便有了有效数字的定义:

**Def-1.2.3**

设$x^*$是某个实数$x$的一个近似值,写作:
$$
x^* =  \pm {10^k} \times 0.{d_1}{d_2} \cdots {d_i} \cdots  =  \pm {10^k} \times \sum\limits_{j = 1} {\left( {{d_j} \times {{10}^{ - j}}} \right)}
$$
$x^*$可以是有限小数或者无限小数,都可以.其中每一个dd(草)都是$$0$$到$$9$$的一位整数(十进制写法),并且要求${d_1} \ne 0$并且$k \in \mathbb{Z}$,如果自然数$n$满足:
$$
\varepsilon \left( {x^*} \right) \leqslant \frac{1}{2} \times {10^{k - n}}
$$
则将满足上述不等式的最大的自然数放到下描述中:

$x$具有的一个$n$位**十进制有效数字**的近似值.

常数$R = 8.314472{\text{J}} \cdot {\text{mo}}{{\text{l}}^{ - 1}} \cdot {{\text{K}}^{ - 1}}$的近似值之一$8.31 = {10^1} \times 0.831$容易知道此情形$k = 1,n = 3$时有:

$\left| {R - 8.31} \right| = 0.004472 \leqslant 0.5 \times {10^{1 - 3}}$,所以使用值$$8.31$$来近似常数$R$有三位有效数字.

常数${N_A} = 6.02214076 \times {10^{23}}{\text{mo}}{{\text{l}}^{ - 1}}$的近似值之一$6.02 \times {10^{23}} = {10^{24}} \times 0.602$容易知道此情形$k = 24,n = 3$时有:

$\left| {{N_A} - 6.02 \times {{10}^{23}}} \right| = 0.214076 \times {10^{21}} \leqslant 0.5 \times {10^{24 - 3}}$,所以使用值$$6.02×10^{23}$$来近似常数有三位有效数字.

够透彻吗?

如果说有效数字是被误差定义的,那它和误差有什么相互决定的关系吗?如果说绝对误差限给到的信息还是有限,那相对误差限与有效数字存在关系吗?

答案是肯定的.

关于相对误差限和有效数字位我们有如下定理.

**Thm-1.2.1**

设$x^*$是某个实数$x$的一个近似值,写作:
$$
x^* =  \pm {10^k} \times 0.{d_1}{d_2} \cdots {d_i} \cdots  =  \pm {10^k} \times \sum\limits_{j = 1} {\left( {{d_j} \times {{10}^{ - j}}} \right)}
$$
并且要求${d_1} \ne 0$并且$k \in \mathbb{Z}$,若$x^*$有$n$位有效数字,则其相对误差限满足:
$$
\varepsilon _r^* \leqslant \frac{1}{{2{d_1}}} \times {10^{1 - n}}
$$
反之,若$x^*$的相对误差限满足下述条件:
$$
\varepsilon _r^* \leqslant \frac{1}{{2\left( {1 + {d_1}} \right)}} \times {10^{1 - n}}
$$
则$x^*$至少有$n$位有效数字.

证明:

先证正方向,若$x^*$有$n$位有效数字,则其相对误差限为:$\varepsilon _r^* = \frac{\eta }{{\left| {x^*} \right|}}$,且同时满足$\eta  \leqslant \frac{1}{2} \times {10^{k - n}}$,因此:

$$
\varepsilon _r^* \leqslant \frac{{{{10}^{k - n}}}}{{2\left| {x^*} \right|}} = \frac{{{{10}^{k - n}}}}{{2 \times {{10}^k} \times \sum\limits_{j = 1} {\left( {{d_j} \times {{10}^{ - j}}} \right)} }} \leqslant \frac{1}{{2{d_1}}} \times {10^{1 - n}}
$$
正方向得证.

再证反方向,若$x^*$的相对误差限满足$\varepsilon _r^* \leqslant \frac{1}{{2\left( {1 + {d_1}} \right)}} \times {10^{1 - n}}$,因此:
$$
\varepsilon _r^* \leqslant \frac{1}{{2\left( {1 + {d_1}} \right)}} \times {10^{1 - n}} \leqslant \frac{{{{10}^k}}}{{2 \times {{10}^{k + 1}} \times \sum\limits_{j = 1} {\left( {{d_j} \times {{10}^{ - j}}} \right)} }} \times {10^{1 - n}} = \frac{{{{10}^{k - n}}}}{{2\left| {x^*} \right|}}
$$
则$x^*$至少有$n$位有效数字.反方向得证.我们还是来举一个例子.

**E.G.-1.2.2**

我们要使得$\sqrt2$近似值的相对误差不大于$0.1\%$,我们应该取几位有效数字?由上述定理知道:

$$
\varepsilon _r^* \leqslant \frac{1}{{2{d_1}}} \times {10^{1 - n}} = \frac{1}{2} \times {10^{1 - n}}\quad \left\{ {{d_1} = 1} \right\}
$$
取$n=4$就可以保证误差控制.

更令人烦恼的是,误差并不仅仅只会存在于计算过程中.在数据的加和和处理之中,所有的误差都会被传递到后续的结果中,给估计值带来影响.譬如最简单的四则运算中都会将误差不断地传递:
$$
\varepsilon \left( {{x_1} \pm {x_2}} \right) = \left| {\left( {x_1^* \pm x_2^*} \right) - \left( {{x_1} \pm {x_2}} \right)} \right| \leqslant \left| {x_1^* - {x_1}} \right| + \left| {x_2^* - {x_2}} \right| = {\varepsilon _1} + {\varepsilon _2}
$$
有没有一个更一般的结论呢?如果我们假设一个一元函数$f$具有二阶连续导数,自变量$x$的一个近似值为$x^*$,可以使用Taylor公式在$x^*$附近展开至二阶余项:
$$
f(x) = f(x^*) + f'(x^*)(x - x^*) + \frac{1}{2}f''(\xi ){(x - x^*)^2}
$$
移项之后加上绝对值可以得到:
$$
\left| {f(x) - f(x^*)} \right| = \left| {f'(x^*)(x - x^*) + \frac{1}{2}f''(\xi ){{(x - x^*)}^2}} \right|
$$
再使用绝对值不等式放缩就可以得到:
$$
\left| {f(x) - f(x^*)} \right| \leqslant \left| {f'(x^*)} \right|\left| {x - x^*} \right| + \frac{1}{2}\left| {f''(\xi )} \right|{\left| {x - x^*} \right|^2}
$$
我们知道$\xi$处于$x$与$x^*$之间,那么如果这个一阶导数$f'(x^*)$不为零,并且二阶导数$\abs{f''(x^*)}$与一阶导数$\abs{f'(x^*)}$相比并不很大,那么二次高阶项就可以直接被忽略,上述不等式就可以直接被写成如下形式:
$$
\left| {f(x) - f(x^*)} \right| \leqslant \left| {f'(x^*)} \right|\left| {x - x^*} \right|
$$
因此可以得到$f(x)$的绝对误差界为:$\left| {f'(x*)} \right|\varepsilon $.我们来举一个例子.

**E.G.-1.2.3**

设有正实数$x$,并且有正的近似值$x^*$,其相对误差界为$\varepsilon$,那么估计$\ln x$的误差?

好办啊,那么这绝对误差界就可以取$\varepsilon \left| {x^*} \right| = \varepsilon x^*$,直接给你进行一个差的作:
$$
\left| {\ln x - \ln x^*} \right| \leqslant \left| {f'(x^*)} \right|\left| {x - x^*} \right| \leqslant \frac{1}{{x^*}} \cdot \varepsilon x^* = \varepsilon 
$$
所以相对$\ln x$误差界可以直接写成$\frac{\varepsilon }{{\left| {\ln x^*} \right|}}$

更一般地,如果$f$是$n$元函数，自变量$x_1,x_2,\cdots,x_n$的近似值为$x^*_1,x_2^*,\cdots,x_n^*$，

则用Taylor公式可以直接展开到一阶(高阶项太恶心了我就不写了好吧):
$$
f\left( {{x_1},{x_2}, \cdots {x_n}} \right) \approx f\left( {x_1^*,x_2^*, \cdots x_n^*} \right) + \sum\limits_{k = 1}^n {{{\left( {\frac{{\partial f}}{{\partial {x_k}}}} \right)}_*}({x_k} - x_k^*)} 
$$

这样移项就可以估计到函数值的近似误差界,我们有:
$$
\left| {f\left( {{x_1},{x_2}, \cdots {x_n}} \right) - f\left( {x_1^*,x_2^*, \cdots x_n^*} \right)} \right| \leqslant \sum\limits_{k = 1}^n {\left| {{{\left( {\frac{{\partial f}}{{\partial {x_k}}}} \right)}_*}}\right|\left| {{x_k} - x_k^*} \right|}
$$

## **1.3 数值稳定性**

从上面例子我们已经看到,误差毕竟是会在计算过程中传播的,因此一定要小心地选择计算的方法,不同的方法队误差的传递作用可能是不同的.如果我们要计算一个定积分:

$$
{I_n} = \int_0^1 {{x^n}{e^{x - 1}}{\text{d}}x} ,n = 0,1, \cdots ,N
$$
怎么估计它的误差?由分部积分法我们可以得到:
$$
{I_n} = \int_0^1 {{x^n}{e^{x - 1}}{\text{d}}x}  = \left. {{x^n}{e^{x - 1}}} \right|_0^1 - \int_0^1 {n{x^{n - 1}}{e^{x - 1}}{\text{d}}x}  = 1 - n{I_{n - 1}}
$$
另外容易知道:
$$
{I_0} = \int_0^1 {{e^{x - 1}}{\text{d}}x}  = 1 - {e^{ - 1}}
$$
所以我们同时利用本值和上面已经得到的递推公式就可以计算了!一切看起来好像都非常的美好.我们要算久一点,就算到${I_8}$吧！初值${I_0} = 1 - {e^{ - 1}} \approx 0.6321$也取到四位.但是荒唐的事情出现了,我们用递推算得${I_8} =  - 0.7280$，${I_9} = 7.552$

被积函数${x^n}{e^{x - 1}}$显然在$$0，1$$之间,这个积分的值显然也不会跑到$$0，1$$之外,但是上面两个值已经出现了如此荒谬的结果,可以看到第一步选择四位有效数字初值的舍入误差已经造成了不可挽回的错误,这种算法在舍入误差的影响下迅速病态增长.

这看似正常的算法出现了什么问题?我们不妨再看一个方法:把递推公式先颠倒过来:

$$
{I_{n - 1}} = \frac{{1 - {I_n}}}{n}
$$
但问题是我们需要事先给出${I_N}$的一个估计值,其实做一个很粗糙的估计也可以,大不了我们用极大极小值做一次放缩.根据Riemann积分的上下界性质我们可以得到如下的不等式:
$$
\frac{{{e^{ - 1}}}}{{N + 1}} = {e^{ - 1}}\mathop {\min }\limits_{0 \leqslant x \leqslant 1} {e^x}\int_0^1 {{e^x}{x^N}{\text{d}}x}  \leqslant \int_0^1 {{e^{x - 1}}{x^N}{\text{d}}x}  \leqslant {e^{ - 1}}\mathop {\max }\limits_{0 \leqslant x \leqslant 1} {e^x}\int_0^1 {{e^x}{x^N}{\text{d}}x}  \leqslant \frac{1}{{N + 1}}
$$
我们可以做一个很粗糙的初值估计:
$$
{\tilde I_9} = \frac{1}{2}\left( {\frac{{{e^{ - 1}} + 1}}{{10}}} \right) \approx 0.0684
$$
迭代回去：${\tilde I_8} = 0.1035, \cdots {\tilde I_1} = 0.3679,{\tilde I_0} = 0.6321$.惊不惊喜?意不意外?实际上,使用粗糙的初值我们能够得到很好的估计,这种现象就自然说明了选择算法的重要性.分析一下这两个算法我们能够得到:$\left| {e_n^*} \right| = n!\left| {e_0^*} \right|$这意味着如果正向计算,误差呈现Gamma级的恶性增长,然而逆向计算是稳定的.所以说第一个算法是不稳定的,第二个算法是稳定的,我们定义:

**Def-1.3.1**

若在计算过程中存在一个与计算步数无关的常数$C$,使得$\left| {{e_n}} \right| \leqslant C\left| {{e_0}} \right|$,则称这个算法是**数值稳定**的,否则就是**数值病态**的.

所以在计算中我们有几个很基本但很重要的法则:
```tip
1.避免用绝对值很大的数去除绝对值很小的数,这是计算机计算过程中的问题,能够保证我们并不会随意丢失计算数值的有效数位.
```
```tip
2.避免将两个数值接近的数相减,原因在于这样会丢失有效数字的位数,譬如解:${x^2} - 16x + 1 = 0$的小正根,结果应该是$8 - \sqrt {63} $,如果在计算过程中使用的是只有三位有效数字字长的计算器,那么$8 - \sqrt {63}  \approx 8.00 - 7.94 = 0.06$就会丢失数据.
```
如果使用$8 - \sqrt {63}  = \frac{1}{{8 + \sqrt {63} }} \approx \frac{1}{{8.00 + 7.94}} \approx 0.0627$三位有效数字不就保下了吗?
```tip
3.避免用绝对值很大的数与绝对值很小的数相加减.
```
譬如说计算下面的例子:$A = 10000 + \sum\limits_{i = 1}^{1000} {\left| {{\delta _i}} \right|,} \left| {{\delta _i}} \right| \leqslant 0.4$,如果你直接逐项相加,那不好意思,后面那坨小的数都在计算过程中被修约掉了，结果显然严重失真.如果你先算后面那坨小数字的和,那么至少能得到一个在$$10400$$与$$10000$$之间的合理数值.
```tip
4.注意优化算法,适当简化自己计算方法的步骤.
```
请注意现在已经要涉及到操作计算机或者计算软件来完成我们的计算工作,因此若是要计算某些很复杂的数值问题,若是不对算法进行优化,那可能会出现时长爆炸的不良情形,因此我们需要更简便的算法保证计算的高效性,例如计算多项式:
$$
{P_n}\left( x \right) = \sum\limits_{k = 0}^n {{a_k}{x^k}}
$$
如果把各项算好了之后再相加,那么需要计算$n$次加法与$\frac{{n(n + 1)}}{2}$次乘法.

如果使用著名的秦九韶算法:${S_n} = {a_n}$，${S_{k - 1}} = k{S_k} + {a_{k - 1}}$,最终有$A = {S_0}$,此时计算也就只需要次$n$加法与$n$次乘法了.

又或是说用Taylor级数计算$\ln2$,如果使用一般的计算方法:
$$
\ln (1 + x) = \sum\limits_{n = 1}^\infty  {{{( - 1)}^{n + 1}}\frac{{{x^n}}}{n}}
$$
那不好意思,你精确到$10^{-5}$需要计算十万项求和.

如果采用如下方法:
$$
\ln \frac{{1 + x}}{{1 - x}} = 2\sum\limits_{n = 1}^\infty  {\frac{{{x^{2n - 1}}}}{{2n - 1}}} 
$$
取$x = \frac{1}{3}$,你只需要计算前$$9$$项,就可以让截断误差低于${10^{ - 10}}$.

你还要问为什么我要学数值分析吗?

**参考文献:** 

［1］  数值线性代数.徐树方.高立,高平文.北京大学出版社,2013,1(2):2
［2］  数值分析基础.关治,陆金甫.高等教育出版社,2019,5(3)
